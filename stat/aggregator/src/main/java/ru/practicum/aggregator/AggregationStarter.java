package ru.practicum.aggregator;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.consumer.Consumer;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.errors.WakeupException;
import org.springframework.stereotype.Component;
import ru.practicum.aggregator.config.AggregatorProperties;
import ru.practicum.aggregator.logic.AggregatorRepository;
import ru.practicum.ewm.stats.avro.EventSimilarityAvro;
import ru.practicum.ewm.stats.avro.UserActionAvro;

import java.time.Duration;
import java.util.HashMap;
import java.util.List;
import java.util.Map;



@RequiredArgsConstructor
@Component
@Slf4j
public class AggregationStarter {

    private final KafkaConsumer<Long, UserActionAvro> consumer;
    private final Producer<Long, EventSimilarityAvro> producer;
    private final AggregatorRepository aggregator; // —Ç–≤–æ—è –ª–æ–≥–∏–∫–∞ –ø–µ—Ä–µ—Ä–∞—Å—á—ë—Ç–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞
    private final AggregatorProperties props;
    private static final Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();
    private static final int COUNT_FIX_OFFSETS = 10;

    public void start() {
        validateProps();

        final String inputTopic = props.getUserActions();
        final String outputTopic = props.getEventsSimilarity();
        final Duration pollTimeout = Duration.ofMillis(
                props.getPollTimeoutMs() != null ? props.getPollTimeoutMs() : 5000
        );

        consumer.subscribe(List.of(inputTopic));
        log.info("üì• –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Ç–æ–ø–∏–∫: {}", inputTopic);

        try {
            Runtime.getRuntime().addShutdownHook(new Thread(consumer::wakeup));
            for (;;) {
                var records = consumer.poll(pollTimeout);
                if (records.isEmpty()) continue;

                records.forEach(record -> {
                    var event = record.value();
                    if (event == null) {
                        log.warn("‚ö† –ü—Ä–æ–ø—É—â–µ–Ω–æ –ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (partition={}, offset={})",
                                record.partition(), record.offset());
                        return;
                    }

                    log.debug("‚û° userId={}, eventId={}, action={}",
                            event.getUserId(), event.getEventId(), event.getActionType());

                    int count = 0;

                    for (EventSimilarityAvro sim : aggregator.updateEventSimilarity(event)) {
                        producer.send(
                                new ProducerRecord<>(outputTopic,null ,sim.getTimestamp().toEpochMilli(),sim.getEventA() , sim),
                                (md, ex) -> {
                                    if (ex != null) {
                                        log.error("‚ùå send similarity fail (key={}): {}",
                                                sim.getTimestamp().toEpochMilli(), ex.getMessage(), ex);
                                    } else {
                                        log.debug("‚úÖ similarity sent: topic={}, partition={}, offset={}",
                                                md.topic(), md.partition(), md.offset());
                                    }
                                }
                        );
                        manageOffsets(record, count, consumer);
                    }
                });

//                // –æ–¥–∏–Ω –æ–±—â–∏–π –∫–æ–º–º–∏—Ç –∑–∞ –ø–∞—á–∫—É
//                consumer.commitAsync((offsets, ex) -> {
//                    if (ex != null) log.warn("‚ö† commitAsync error: {}", ex.getMessage(), ex);
//                });
            }

        } catch (WakeupException ignored) {
            log.info("‚õî –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (Wakeup)");
        } catch (Exception e) {
            log.error("üí• –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏", e);
        } finally {
            try {
                consumer.commitSync();
            } catch (Exception e) {
                log.warn("‚ö† –û—à–∏–±–∫–∞ commitSync –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏: {}", e.getMessage(), e);
            }
            // –∑–∞–∫—Ä—ã–≤–∞–µ–º consumer/producer –∞–∫–∫—É—Ä–∞—Ç–Ω–æ
            safeCloseConsumer();
            safeCloseProducer();
        }
    }

    private void validateProps() {
        if (isBlank(props.getEventsSimilarity()) || isBlank(props.getUserActions())) {
            throw new IllegalStateException("Kafka topics –Ω–µ —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω—ã: inputTopic=" +
                    props.getUserActions() + ", outputTopic=" + props.getEventsSimilarity());
        }
    }

    private void manageOffsets(ConsumerRecord<Long, UserActionAvro> record, int count, Consumer<Long, UserActionAvro> consumer) {
        // –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –æ—Ñ—Ñ—Å–µ—Ç –¥–ª—è —Ç–æ–ø–∏–∫–∞-–ø–∞—Ä—Ç–∏—Ü–∏–∏
        currentOffsets.put(
                new TopicPartition(record.topic(), record.partition()),
                new OffsetAndMetadata(record.offset() + 1)
        );

        if (count % COUNT_FIX_OFFSETS == 0) {
            consumer.commitAsync(currentOffsets, (offsets, exception) -> {
                if (exception != null) {
                    log.warn("Error during offset fixing: {}", offsets, exception);
                }
            });
        }
    }

    private boolean isBlank(String s) {
        return s == null || s.isBlank();
    }

    private void safeCloseConsumer() {
        try {
            consumer.close();
            log.info("üì¥ Consumer –∑–∞–∫—Ä—ã—Ç");
        } catch (Exception e) {
            log.warn("‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ consumer: {}", e.getMessage(), e);
        }
    }

    private void safeCloseProducer() {
        try {
            producer.flush();
        } catch (Exception e) {
            log.warn("‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ flush producer: {}", e.getMessage(), e);
        }
        try {
            producer.close();
            log.info("üì§ Producer –∑–∞–∫—Ä—ã—Ç");
        } catch (Exception e) {
            log.warn("‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ producer: {}", e.getMessage(), e);
        }
    }

}
